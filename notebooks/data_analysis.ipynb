{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.getcwd(), \"data\")\n",
    "seller_items_path = os.path.join(data_path, \"input\", \"seller_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para armazenar os dados\n",
    "data = []\n",
    "\n",
    "# Percorrer todos os arquivos no diretório\n",
    "for filename in os.listdir(seller_items_path):\n",
    "    if filename.endswith(\"_items.json\"):  # Garantir que são arquivos de sellers\n",
    "        file_path = os.path.join(seller_items_path, filename)\n",
    "\n",
    "        # Abrir e ler o arquivo linha por linha\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            for line in file:\n",
    "                try:\n",
    "                    item_data = json.loads(line)  # Converter JSON para dicionário\n",
    "                    data.append(item_data)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Erro ao ler {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar DataFrame do pandas\n",
    "df = pd.DataFrame(data)\n",
    "df[\"available_amount\"] = df[\"price\"] * df[\"available_qty\"]\n",
    "# Exibir as primeiras linhas\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "df_grouped = df.groupby(\"seller_id\").agg(\n",
    "    {\n",
    "        \"category_id\": [\n",
    "            lambda x: list(set(x)),  # Unique categories\n",
    "            lambda x: len(set(x)),  # Number of unique categories\n",
    "            lambda x: (\n",
    "                x.mode().iloc[0] if not x.mode().empty else None\n",
    "            ),  # Most frequent category\n",
    "            lambda x: (\n",
    "                x.value_counts(normalize=True).max() if not x.empty else 0\n",
    "            ),  # Dominant category ratio\n",
    "        ],\n",
    "        \"price\": [\n",
    "            \"count\",\n",
    "            \"mean\",\n",
    "            \"std\",\n",
    "            lambda x: x.mode().iloc[0] if not x.mode().empty else None,  # Mode\n",
    "            lambda x: np.percentile(x, 75)\n",
    "            - np.percentile(x, 25),  # IQR (Interquartile Range)\n",
    "            lambda x: (\n",
    "                np.std(x) / np.mean(x) if np.mean(x) > 0 else 0\n",
    "            ),  # Coefficient of Variation (CV)\n",
    "        ],\n",
    "        \"original_price\": [\"mean\", \"std\"],\n",
    "        \"discount\": [\"mean\", \"std\", \"max\"],\n",
    "        \"available_qty\": [\"sum\", \"mean\", \"std\"],\n",
    "        \"cataloged\": \"sum\",\n",
    "        \"free_shipping\": \"sum\",\n",
    "        \"condition\": lambda x: (\n",
    "            x.mode().iloc[0] if not x.mode().empty else None\n",
    "        ),  # Most frequent condition\n",
    "        \"installments\": [\"mean\", \"std\"],\n",
    "        \"buying_mode\": lambda x: (\n",
    "            x.mode().iloc[0] if not x.mode().empty else None\n",
    "        ),  # Most frequent buying mode\n",
    "        \"city\": [\n",
    "            lambda x: (\n",
    "                x.mode().iloc[0] if not x.mode().empty else None\n",
    "            ),  # Most frequent city\n",
    "        ],\n",
    "        \"state\": lambda x: (\n",
    "            x.mode().iloc[0] if not x.mode().empty else None\n",
    "        ),  # Most frequent state\n",
    "        \"has_gtin\": \"sum\",\n",
    "        \"num_attributes\": [\"mean\", \"std\", \"median\"],  # Product complexity\n",
    "    }\n",
    ")\n",
    "\n",
    "# Rename Columns\n",
    "df_grouped.columns = [\n",
    "    \"unique_categories\",\n",
    "    \"num_categories\",\n",
    "    \"mode_category\",\n",
    "    \"dominant_category_ratio\",\n",
    "    \"total_items\",\n",
    "    \"price_mean\",\n",
    "    \"price_std\",\n",
    "    \"price_mode\",\n",
    "    \"price_iqr\",\n",
    "    \"price_cv\",\n",
    "    \"original_price_mean\",\n",
    "    \"original_price_std\",\n",
    "    \"discount_mean\",\n",
    "    \"discount_std\",\n",
    "    \"discount_max\",\n",
    "    \"available_qty_sum\",\n",
    "    \"available_qty_mean\",\n",
    "    \"available_qty_std\",\n",
    "    \"cataloged_sum\",\n",
    "    \"free_shipping_sum\",\n",
    "    \"condition_mode\",\n",
    "    \"installments_mean\",\n",
    "    \"installments_std\",\n",
    "    \"buying_mode_mode\",\n",
    "    \"most_frequent_city\",\n",
    "    \"most_frequent_state\",\n",
    "    \"has_gtin_sum\",\n",
    "    \"num_attributes_mean\",\n",
    "    \"num_attributes_std\",\n",
    "    \"num_attributes_median\",\n",
    "]\n",
    "\n",
    "df_grouped = df_grouped.reset_index()\n",
    "\n",
    "# Compute proportions\n",
    "df_grouped[\"proportion_cataloged\"] = (\n",
    "    df_grouped[\"cataloged_sum\"] / df_grouped[\"total_items\"]\n",
    ")\n",
    "df_grouped[\"proportion_free_shipping\"] = (\n",
    "    df_grouped[\"free_shipping_sum\"] / df_grouped[\"total_items\"]\n",
    ")\n",
    "df_grouped[\"proportion_has_gtin\"] = (\n",
    "    df_grouped[\"has_gtin_sum\"] / df_grouped[\"total_items\"]\n",
    ")\n",
    "\n",
    "# Compute the count of \"new\" condition for each seller\n",
    "df_grouped[\"condition_new_count\"] = df.groupby(\"seller_id\")[\"condition\"].apply(\n",
    "    lambda x: (x == \"new\").sum()  # Count how many \"new\" conditions\n",
    ")\n",
    "\n",
    "# Compute the proportion of \"new\" condition\n",
    "df_grouped[\"proportion_new\"] = (\n",
    "    df_grouped[\"condition_new_count\"] / df_grouped[\"total_items\"]\n",
    ")\n",
    "\n",
    "# Compute the count of \"buy_it_now\" buying mode for each seller\n",
    "df_grouped[\"buying_mode_buy_it_now_count\"] = df.groupby(\"seller_id\")[\n",
    "    \"buying_mode\"\n",
    "].apply(\n",
    "    lambda x: (x == \"buy_it_now\").sum()  # Count how many \"buy_it_now\" modes\n",
    ")\n",
    "\n",
    "# Compute the proportion of \"buy_it_now\"\n",
    "df_grouped[\"proportion_buy_it_now\"] = (\n",
    "    df_grouped[\"buying_mode_buy_it_now_count\"] / df_grouped[\"total_items\"]\n",
    ")\n",
    "\n",
    "# Compute items per category\n",
    "df_grouped[\"items_per_category\"] = (\n",
    "    df_grouped[\"total_items\"] / df_grouped[\"num_categories\"]\n",
    ")\n",
    "\n",
    "# Compute frequency of each city in the dataset\n",
    "city_counts = df[\"city\"].value_counts(normalize=True).to_dict()\n",
    "\n",
    "# Map city frequencies to df_grouped based on the most frequent city of each seller\n",
    "df_grouped[\"city_frequency\"] = df_grouped[\"most_frequent_city\"].map(city_counts)\n",
    "\n",
    "# Compute frequency of each city in the dataset\n",
    "category_counts = df[\"category_id\"].value_counts(normalize=True).to_dict()\n",
    "\n",
    "# Map city frequencies to df_grouped based on the most frequent city of each seller\n",
    "df_grouped[\"category_frequency\"] = df_grouped[\"mode_category\"].map(category_counts)\n",
    "\n",
    "# Count distinct cities per seller\n",
    "df_grouped[\"distinct_cities_count\"] = (\n",
    "    df.groupby(\"seller_id\")[\"city\"].nunique().reset_index()[\"city\"]\n",
    ")\n",
    "\n",
    "display(df_grouped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fields = df_grouped[\n",
    "    [\n",
    "        # \"unique_categories\",\n",
    "        \"num_categories\",\n",
    "        # \"mode_category\",\n",
    "        \"category_frequency\",\n",
    "        \"dominant_category_ratio\",\n",
    "        \"total_items\",\n",
    "        \"price_mean\",\n",
    "        \"price_std\",\n",
    "        \"price_mode\",\n",
    "        \"price_iqr\",\n",
    "        \"price_cv\",\n",
    "        \"original_price_mean\",\n",
    "        \"original_price_std\",\n",
    "        \"discount_mean\",\n",
    "        \"discount_std\",\n",
    "        \"discount_max\",\n",
    "        # \"available_qty_sum\",\n",
    "        \"available_qty_mean\",\n",
    "        \"available_qty_std\",\n",
    "        # \"cataloged_sum\",\n",
    "        \"proportion_cataloged\",\n",
    "        # \"free_shipping_sum\",\n",
    "        \"proportion_free_shipping\",\n",
    "        \"condition_mode\",\n",
    "        \"proportion_new\",\n",
    "        \"installments_mean\",\n",
    "        \"installments_std\",\n",
    "        \"buying_mode_mode\",\n",
    "        \"proportion_buy_it_now\",\n",
    "        \"most_frequent_city\",\n",
    "        \"distinct_cities_count\",\n",
    "        \"proportion_has_gtin\",\n",
    "        \"num_attributes_mean\",\n",
    "        \"num_attributes_std\",\n",
    "        \"num_attributes_median\",\n",
    "    ]\n",
    "]\n",
    "display(df_fields.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a column is numeric\n",
    "def is_numeric(col):\n",
    "    return pd.api.types.is_numeric_dtype(col)\n",
    "\n",
    "\n",
    "# Iterate through the columns and apply frequency encoding if not numeric\n",
    "for column in df_fields.columns:\n",
    "    if not is_numeric(df_fields[column]):\n",
    "        # Apply frequency encoding to non-numeric columns\n",
    "        freq_encoding = df_fields[column].value_counts(normalize=True).to_dict()\n",
    "        df_fields.loc[:, column] = df_fields[column].map(\n",
    "            freq_encoding\n",
    "        )\n",
    "\n",
    "display(df_fields.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔹 Passo 1: Selecionar as features relevantes\n",
    "df_fields = df_fields.copy()  # Criar uma cópia para evitar avisos de mutação\n",
    "\n",
    "# 🔹 Passo 2: Aplicar Frequency Encoding nas variáveis categóricas\n",
    "# categorical_cols = [\"most_frequent_city\"]\n",
    "# for col in categorical_cols:\n",
    "#     freq_map = df_fields[col].value_counts(normalize=True).to_dict()\n",
    "#     df_fields[col] = df_fields[col].map(freq_map)\n",
    "\n",
    "df_fields = df_fields.fillna(0)\n",
    "\n",
    "# # 🔹 Passo 3: Remover Outliers usando Z-score\n",
    "# z_scores = np.abs(stats.zscore(df_fields))\n",
    "# df_filtered = df_fields[\n",
    "#     (z_scores < 3).all(axis=1)\n",
    "# ]  # Mantém apenas valores dentro de 3 desvios padrão\n",
    "\n",
    "# 🔹 Passo 4: Normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_fields)\n",
    "\n",
    "# 🔹 Passo 5: Encontrar o número ideal de clusters (Método do Cotovelo)\n",
    "inertia = []\n",
    "K_range = range(1, 16)  # Testando de 1 a 10 clusters\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# 🔹 Passo 6: Plotar o Método do Cotovelo\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(K_range, inertia, marker=\"o\", linestyle=\"-\")\n",
    "plt.title(\"Método do Cotovelo\")\n",
    "plt.xlabel(\"Número de Clusters (k)\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔹 Passo 7: Aplicar K-Means com k escolhido (exemplo: k=4)\n",
    "kmeans = KMeans(n_clusters=8, random_state=42)\n",
    "df_fields[\"cluster\"] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# 🔹 Passo 8: Visualizar os primeiros vendedores e seus clusters\n",
    "df_fields.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔹 Passo 1: Reduzir para 3 dimensões com PCA\n",
    "pca = PCA(n_components=3)\n",
    "X_pca_3d = pca.fit_transform(X_scaled)\n",
    "\n",
    "# 🔹 Passo 2: Normalizar os componentes principais\n",
    "scaler_pca = StandardScaler()\n",
    "X_pca_3d_normalized = scaler_pca.fit_transform(X_pca_3d)\n",
    "\n",
    "# 🔹 Passo 3: Criar gráfico 3D com Plotly\n",
    "df_pca_normalized = pd.DataFrame(X_pca_3d_normalized, columns=[\"PC1\", \"PC2\", \"PC3\"])\n",
    "df_pca_normalized[\"cluster\"] = df_fields[\"cluster\"]\n",
    "\n",
    "# Criar o gráfico interativo\n",
    "fig = px.scatter_3d(\n",
    "    df_pca_normalized,\n",
    "    x=\"PC1\",\n",
    "    y=\"PC2\",\n",
    "    z=\"PC3\",\n",
    "    color=\"cluster\",\n",
    "    title=\"Clusters de Vendedores (PCA 3D - Normalizado)\",\n",
    "    labels={\n",
    "        \"PC1\": \"Componente Principal 1 (Normalizado)\",\n",
    "        \"PC2\": \"Componente Principal 2 (Normalizado)\",\n",
    "        \"PC3\": \"Componente Principal 3 (Normalizado)\",\n",
    "    },\n",
    "    color_continuous_scale=\"viridis\",\n",
    ")\n",
    "\n",
    "# Exibir o gráfico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_pca_3d_normalized is your PCA-transformed data\n",
    "# Get the indices of the top 3 highest values from each PCA column (PCA1, PCA2, PCA3)\n",
    "top_indices_pca1 = np.argsort(X_pca_3d_normalized[:, 0])[::-1][\n",
    "    :3\n",
    "]  # Top 3 indices for PCA1\n",
    "top_indices_pca2 = np.argsort(X_pca_3d_normalized[:, 1])[::-1][\n",
    "    :3\n",
    "]  # Top 3 indices for PCA2\n",
    "top_indices_pca3 = np.argsort(X_pca_3d_normalized[:, 2])[::-1][\n",
    "    :3\n",
    "]  # Top 3 indices for PCA3\n",
    "\n",
    "# Combine all top indices (ensure uniqueness)\n",
    "top_indices = np.unique(\n",
    "    np.concatenate([top_indices_pca1, top_indices_pca2, top_indices_pca3])\n",
    ")\n",
    "\n",
    "# Remove outliers (top 3 highest values for each PCA column) from df_fields\n",
    "df_fields = df_fields.drop(top_indices).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_fields.iloc[top_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scaler.fit_transform(df_fields.drop(\"cluster\", axis=1))\n",
    "\n",
    "# 🔹 Passo 5: Encontrar o número ideal de clusters (Método do Cotovelo)\n",
    "inertia = []\n",
    "K_range = range(1, 16)  # Testando de 1 a 10 clusters\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# 🔹 Passo 6: Plotar o Método do Cotovelo\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(K_range, inertia, marker=\"o\", linestyle=\"-\")\n",
    "plt.title(\"Método do Cotovelo\")\n",
    "plt.xlabel(\"Número de Clusters (k)\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔹 Passo 7: Aplicar K-Means com k escolhido (exemplo: k=4)\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "df_fields[\"cluster\"] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# 🔹 Passo 8: Visualizar os primeiros vendedores e seus clusters\n",
    "df_fields.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔹 Passo 1: Reduzir para 3 dimensões com PCA\n",
    "pca = PCA(n_components=3)\n",
    "X_pca_3d = pca.fit_transform(X_scaled)\n",
    "\n",
    "# 🔹 Passo 2: Normalizar os componentes principais\n",
    "scaler_pca = StandardScaler()\n",
    "X_pca_3d_normalized = scaler_pca.fit_transform(X_pca_3d)\n",
    "\n",
    "# 🔹 Passo 3: Criar gráfico 3D com Plotly\n",
    "df_pca_normalized = pd.DataFrame(X_pca_3d_normalized, columns=[\"PC1\", \"PC2\", \"PC3\"])\n",
    "df_pca_normalized[\"cluster\"] = df_fields[\"cluster\"]\n",
    "\n",
    "# Criar o gráfico interativo\n",
    "fig = px.scatter_3d(\n",
    "    df_pca_normalized,\n",
    "    x=\"PC1\",\n",
    "    y=\"PC2\",\n",
    "    z=\"PC3\",\n",
    "    color=\"cluster\",\n",
    "    title=\"Clusters de Vendedores (PCA 3D - Normalizado)\",\n",
    "    labels={\n",
    "        \"PC1\": \"Componente Principal 1 (Normalizado)\",\n",
    "        \"PC2\": \"Componente Principal 2 (Normalizado)\",\n",
    "        \"PC3\": \"Componente Principal 3 (Normalizado)\",\n",
    "    },\n",
    "    color_continuous_scale=\"viridis\",\n",
    ")\n",
    "\n",
    "# Exibir o gráfico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o gráfico interativo para cada cluster\n",
    "for cluster in list(set(df_pca_normalized[\"cluster\"])):\n",
    "    fig = px.scatter_3d(\n",
    "        df_pca_normalized[df_pca_normalized[\"cluster\"] == cluster],\n",
    "        x=\"PC1\",\n",
    "        y=\"PC2\",\n",
    "        z=\"PC3\",\n",
    "        color=\"cluster\",\n",
    "        title=f\"Clusters de Vendedores (PCA 3D - Normalizado) - Cluster {cluster}\",\n",
    "        labels={\n",
    "            \"PC1\": \"Componente Principal 1 (Normalizado)\",\n",
    "            \"PC2\": \"Componente Principal 2 (Normalizado)\",\n",
    "            \"PC3\": \"Componente Principal 3 (Normalizado)\",\n",
    "        },\n",
    "        color_continuous_scale=\"viridis\",\n",
    "    )\n",
    "\n",
    "    # Exibir o gráfico\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter a matriz de cargas (loadings)\n",
    "pca_components = pd.DataFrame(\n",
    "    pca.components_,  # Coeficientes do PCA\n",
    "    columns=df_fields.drop(columns='cluster').columns,  # Nome das variáveis originais\n",
    "    index=[f\"PC{i+1}\" for i in range(pca.n_components_)],  # Nome dos componentes\n",
    ")\n",
    "\n",
    "# Exibir a matriz de cargas dos 3 primeiros PCs\n",
    "pca_components.T.sort_values(by=\"PC1\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fields.columns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fields.drop(columns=\"cluster\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_summary = df_fields.groupby(\"cluster\").mean()\n",
    "df_cluster_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_summary.T.sort_values(\n",
    "    by=0, ascending=False\n",
    ")  # Ordena pela média do cluster 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis numéricas para gerar boxplots\n",
    "numeric_cols = df_cluster_summary.columns\n",
    "\n",
    "# Gerar boxplots para cada variável numérica\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(x=df_fields[\"cluster\"], y=df_fields[col])\n",
    "    plt.title(f\"Distribuição de {col} por Cluster\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_fields is your DataFrame and has a 'cluster' column\n",
    "X = df_fields.drop(columns=\"cluster\").values  # Features\n",
    "y = df_fields[\"cluster\"].values  # Labels (or clusters)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Perform PCA with 2 components for visualization\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "\n",
    "# Create a Plotly biplot\n",
    "def plot_biplot(score, coeff, labels=None):\n",
    "    xs = score[:, 0]\n",
    "    ys = score[:, 1]\n",
    "    n = coeff.shape[0]\n",
    "\n",
    "    # Create the figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Scatter plot for the PCA scores (data points)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=xs,\n",
    "            y=ys,\n",
    "            mode=\"markers\",\n",
    "            marker=dict(\n",
    "                color=y, colorscale=\"Viridis\", showscale=True\n",
    "            ),  # Color by clusters\n",
    "            name=\"PCA points\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Adding arrows for each feature (vectors)\n",
    "    for i in range(n):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[0, coeff[i, 0]],  # Start from the origin\n",
    "                y=[0, coeff[i, 1]],  # End at the component direction\n",
    "                mode=\"lines+text\",\n",
    "                line=dict(color=\"red\", width=2),\n",
    "                text=[\n",
    "                    None,\n",
    "                    labels[i] if labels is not None else f\"Var{i + 1}\",\n",
    "                ],  # Feature label\n",
    "                textposition=\"top center\",\n",
    "                name=f\"Feature {labels[i]}\" if labels is not None else f\"Var{i + 1}\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Layout settings\n",
    "    fig.update_layout(\n",
    "        title=\"PCA Biplot - First Two Principal Components\",\n",
    "        xaxis_title=\"PC1\",\n",
    "        yaxis_title=\"PC2\",\n",
    "        showlegend=True,\n",
    "        template=\"plotly_dark\",  # Dark theme (optional)\n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "# Call the plotting function\n",
    "plot_biplot(\n",
    "    X_pca[:, 0:2], pca.components_.T, labels=df_fields.columns\n",
    ")  # Feature names as labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
