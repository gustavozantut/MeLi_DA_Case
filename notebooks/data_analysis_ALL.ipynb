{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "pd.set_option(\"display.float_format\", \"{:.2f}\".format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.getcwd(), \"data\")\n",
    "seller_items_path = os.path.join(data_path, \"input\", \"seller_items\")\n",
    "parquet_file_path = os.path.join(data_path, \"input\", \"sellers_items.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#monta dataframe unificado e salva como parquet para proxiumas execuções\n",
    "\n",
    "# Lista para armazenar os dados\n",
    "data = []\n",
    "\n",
    "if os.path.exists(parquet_file_path):\n",
    "    df = pd.read_parquet(parquet_file_path)\n",
    "else:\n",
    "    # Percorrer todos os subdiretórios no diretório seller_items_path\n",
    "    for subfolder_name in os.listdir(seller_items_path):\n",
    "        subfolder_path = os.path.join(seller_items_path, subfolder_name)\n",
    "        if os.path.isdir(subfolder_path):  # Verificar se é um diretório\n",
    "            # Percorrer todos os arquivos no subdiretório\n",
    "            for filename in os.listdir(subfolder_path):\n",
    "                if filename.endswith(\"_items.json\"):  # Garantir que são arquivos de sellers\n",
    "                    file_path = os.path.join(subfolder_path, filename)\n",
    "\n",
    "                    # Abrir e ler o arquivo linha por linha\n",
    "                    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                        for line in file:\n",
    "                            try:\n",
    "                                item_data = json.loads(line)  # Converter JSON para dicionário\n",
    "                                item_data[\"subfolder_name\"] = subfolder_name  # Adicionar o nome da subpasta\n",
    "                                data.append(item_data)\n",
    "                            except json.JSONDecodeError as e:\n",
    "                                print(f\"Erro ao ler {filename}: {e}\")\n",
    "\n",
    "    # Criar DataFrame do pandas\n",
    "    df = pd.DataFrame(data)\n",
    "    # Salvar o DataFrame como arquivo Parquet\n",
    "    df.to_parquet(os.path.join(data_path, \"input\", \"sellers_items.parquet\"))\n",
    "\n",
    "data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir as primeiras linhas\n",
    "print(df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------data quality------------\n",
    "# Verificar valores nulos\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(f\"{col}: {df[col].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"available_qty\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\n",
    "    \"price\",\n",
    "    \"original_price\",\n",
    "    \"discount\",\n",
    "    \"available_qty\",\n",
    "    \"installments\",\n",
    "    \"num_attributes\",\n",
    "]\n",
    "plt.figure(figsize=(12, 6))\n",
    "for col in numeric_cols:\n",
    "    plt.figure()\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f\"Boxplot de {col}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# dolarize price\n",
    "currencies = {\n",
    "    \"MLB\": \"BRL\",  # Brasil\n",
    "    \"MPE\": \"PEN\",  # Perú\n",
    "    \"MBO\": \"BOB\",  # Bolivia\n",
    "    \"MLU\": \"UYU\",  # Uruguay\n",
    "    \"MLA\": \"ARS\",  # Argentina\n",
    "    \"MPY\": \"PYG\",  # Paraguay\n",
    "    \"MLM\": \"MXN\",  # Mexico\n",
    "}\n",
    "\n",
    "# Function to get conversion rate from API\n",
    "def get_conversion_rate(currency):\n",
    "    data = {\n",
    "        \"BRL\": 0.173,\n",
    "        \"PEN\": 0.269,\n",
    "        \"BOB\": 0.144,\n",
    "        \"UYU\": 0.0229,\n",
    "        \"ARS\": 0.000947,\n",
    "        \"PYG\": 0.000126,\n",
    "        \"MXN\": 0.0485,\n",
    "    }\n",
    "    # url = f\"https://api.exchangerate-api.com/v4/latest/{currency}\"\n",
    "    # response = requests.get(url)\n",
    "    # data = response.json()\n",
    "    # return data[\"rates\"][\"USD\"]\n",
    "    return data[currency]\n",
    "\n",
    "# Function to convert prices to USD\n",
    "def convert_to_usd(price, currency):\n",
    "    conversion_rate = get_conversion_rate(currency)\n",
    "    return price * conversion_rate\n",
    "\n",
    "# Create a dictionary to store conversion rates for each currency\n",
    "conversion_rates = {currency: get_conversion_rate(currency) for currency in currencies.values()}\n",
    "conversion_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply conversion to the dataframe\n",
    "df[\"currency\"] = df[\"subfolder_name\"].map(currencies)\n",
    "df[\"currency_rate\"] = df[\"currency\"].map(conversion_rates)\n",
    "df[\"original_price\"] = df[\"original_price\"].fillna(df[\"price\"])\n",
    "df[\"dollar_price\"] = df[\"price\"] * df[\"currency_rate\"]\n",
    "df[\"dollar_original_price\"] = df[\"original_price\"] * df[\"currency_rate\"]\n",
    "df[\"dollar_discount\"] = df[\"discount\"] * df[\"currency_rate\"]\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\n",
    "    \"dollar_price\",\n",
    "    \"dollar_original_price\",\n",
    "    \"dollar_discount\",\n",
    "    \"available_qty\",\n",
    "    \"installments\",\n",
    "    \"num_attributes\",\n",
    "]\n",
    "plt.figure(figsize=(12, 6))\n",
    "for col in numeric_cols:\n",
    "    plt.figure()\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f\"Boxplot de {col}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------data_preparation-------------\n",
    "# drop col because it has only one value\n",
    "df = df.drop(\n",
    "    columns=[\n",
    "        \"buying_mode\",\n",
    "        \"price\",\n",
    "        \"original_price\",\n",
    "        \"discount\",\n",
    "        \"currency\",\n",
    "        \"currency_rate\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "# calculate total amount available\n",
    "df[\"available_amount\"] = df[\"dollar_price\"] * df[\"available_qty\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df.sort_values(by='dollar_price', ascending=False)\n",
    "df_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df.groupby(\"seller_id\").agg(\n",
    "    {\n",
    "        \"category_id\": [\n",
    "            lambda x: list(set(x)),  # Unique categories\n",
    "            lambda x: len(set(x)),  # Number of unique categories\n",
    "            lambda x: (\n",
    "                x.mode().iloc[0] if not x.mode().empty else None\n",
    "            ),  # Most frequent category\n",
    "            lambda x: (\n",
    "                x.value_counts().max() if not x.empty else 0\n",
    "            ),  # Dominant category ratio\n",
    "        ],\n",
    "        \"dollar_price\": [\n",
    "            \"count\",\n",
    "            \"mean\",\n",
    "            lambda x: np.mean(np.abs(x - np.mean(x))),  # MAE\n",
    "            lambda x: x.mode().iloc[0] if not x.mode().empty else None,  # Mode\n",
    "            lambda x: np.percentile(x, 75)\n",
    "            - np.percentile(x, 25),  # IQR (Interquartile Range)\n",
    "            lambda x: (\n",
    "                np.std(x) / np.mean(x) if np.mean(x) > 0 else 0\n",
    "            ),  # Coefficient of Variation (CV)\n",
    "        ],\n",
    "        \"dollar_original_price\": [\n",
    "            \"mean\",\n",
    "            lambda x: np.mean(np.abs(x - np.mean(x))),\n",
    "        ],  # MAE\n",
    "        \"dollar_discount\": [\"mean\", lambda x: np.mean(np.abs(x - np.mean(x)))],  # MAE\n",
    "        \"available_qty\": [\n",
    "            \"sum\",\n",
    "            \"mean\",\n",
    "            lambda x: np.mean(np.abs(x - np.mean(x))),\n",
    "        ],  # MAE\n",
    "        \"cataloged\": \"sum\",\n",
    "        \"free_shipping\": \"sum\",\n",
    "        \"condition\": lambda x: (\n",
    "            x.mode().iloc[0] if not x.mode().empty else None\n",
    "        ),  # Most frequent condition\n",
    "        \"installments\": [\"mean\", lambda x: np.mean(np.abs(x - np.mean(x)))],  # MAE\n",
    "        # Most frequent buying mode\n",
    "        \"city\": [\n",
    "            lambda x: (\n",
    "                x.mode().iloc[0] if not x.mode().empty else None\n",
    "            ),  # Most frequent city\n",
    "        ],\n",
    "        \"state\": lambda x: (\n",
    "            x.mode().iloc[0] if not x.mode().empty else None\n",
    "        ),  # Most frequent state\n",
    "        \"has_gtin\": \"sum\",\n",
    "        \"num_attributes\": [\n",
    "            \"mean\",\n",
    "            lambda x: np.mean(np.abs(x - np.mean(x))),\n",
    "            \"median\",\n",
    "        ],  # MAE\n",
    "        \"available_amount\": [\n",
    "            \"mean\",\n",
    "            lambda x: np.mean(np.abs(x - np.mean(x))),\n",
    "            \"median\",\n",
    "        ],  # MAE\n",
    "    }\n",
    ")\n",
    "\n",
    "# Rename Columns\n",
    "df_grouped.columns = [\n",
    "    \"unique_categories\",\n",
    "    \"num_categories\",\n",
    "    \"mode_category\",\n",
    "    \"dominant_category_ratio\",\n",
    "    \"dollar_price_count\",\n",
    "    \"dollar_price_mean\",\n",
    "    \"dollar_price_mae\",\n",
    "    \"dollar_price_mode\",\n",
    "    \"dollar_price_iqr\",\n",
    "    \"dollar_price_cv\",\n",
    "    \"dollar_original_price_mean\",\n",
    "    \"dollar_original_price_mae\",\n",
    "    \"dollar_discount_mean\",\n",
    "    \"dollar_discount_mae\",\n",
    "    \"available_qty_sum\",\n",
    "    \"available_qty_mean\",\n",
    "    \"available_qty_mae\",\n",
    "    \"cataloged_sum\",\n",
    "    \"free_shipping_sum\",\n",
    "    \"condition_mode\",\n",
    "    \"installments_mean\",\n",
    "    \"installments_mae\",\n",
    "    \"most_frequent_city\",\n",
    "    \"most_frequent_state\",\n",
    "    \"has_gtin_sum\",\n",
    "    \"num_attributes_mean\",\n",
    "    \"num_attributes_mae\",\n",
    "    \"num_attributes_median\",\n",
    "    \"available_amount_mean\",\n",
    "    \"available_amount_mae\",\n",
    "    \"available_amount_median\",\n",
    "]\n",
    "\n",
    "df_grouped = df_grouped.reset_index()\n",
    "\n",
    "df_grouped[\"total_offers\"] = df.groupby(\"seller_id\")[\"seller_id\"].agg('count').values\n",
    "\n",
    "# Compute proportions\n",
    "df_grouped[\"proportion_cataloged\"] = (\n",
    "    df_grouped[\"cataloged_sum\"] / df_grouped[\"total_offers\"]\n",
    ")\n",
    "df_grouped[\"proportion_free_shipping\"] = (\n",
    "    df_grouped[\"free_shipping_sum\"] / df_grouped[\"total_offers\"]\n",
    ")\n",
    "df_grouped[\"proportion_has_gtin\"] = (\n",
    "    df_grouped[\"has_gtin_sum\"] / df_grouped[\"total_offers\"]\n",
    ")\n",
    "\n",
    "# Compute the count of \"new\" condition for each seller\n",
    "df_grouped[\"condition_new_count\"] = df.groupby(\"seller_id\")[\"condition\"].apply(\n",
    "    lambda x: (x == \"new\").sum()  # Count how many \"new\" conditions\n",
    ").values\n",
    "\n",
    "# Compute the proportion of \"new\" condition\n",
    "df_grouped[\"proportion_new\"] = (\n",
    "    df_grouped[\"condition_new_count\"] / df_grouped[\"total_offers\"]\n",
    ").values\n",
    "\n",
    "# Compute items per category\n",
    "df_grouped[\"items_per_category\"] = (\n",
    "    df_grouped[\"total_offers\"] / df_grouped[\"num_categories\"]\n",
    ")\n",
    "\n",
    "# Compute frequency of each city in the dataset\n",
    "city_counts = df[\"city\"].value_counts().to_dict()\n",
    "\n",
    "# Map city frequencies to df_grouped based on the most frequent city of each seller\n",
    "df_grouped[\"city_frequency\"] = df_grouped[\"most_frequent_city\"].map(city_counts)\n",
    "\n",
    "# Compute frequency of each city in the dataset\n",
    "category_counts = df[\"category_id\"].value_counts().to_dict()\n",
    "\n",
    "# Map category frequencies to df_grouped based on the most frequencies city of each seller\n",
    "df_grouped[\"category_frequency\"] = df_grouped[\"mode_category\"].map(category_counts)\n",
    "\n",
    "# Count distinct cities per seller\n",
    "df_grouped[\"distinct_cities_count\"] = (\n",
    "    df.groupby(\"seller_id\")[\"city\"].nunique().reset_index()[\"city\"]\n",
    ")\n",
    "df_grouped.to_parquet(os.path.join(data_path, \"input\", \"sellers_items_grouped.parquet\"))\n",
    "display(df_grouped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fields_ori = df_grouped[\n",
    "    [\n",
    "        \"num_categories\",\n",
    "        \"category_frequency\",\n",
    "        \"dominant_category_ratio\",\n",
    "        \"dollar_price_mean\",\n",
    "        \"dollar_price_mae\",\n",
    "        \"dollar_price_mode\",\n",
    "        \"dollar_price_iqr\",\n",
    "        \"dollar_price_cv\",\n",
    "        \"dollar_original_price_mean\",\n",
    "        \"dollar_original_price_mae\",\n",
    "        \"dollar_discount_mean\",\n",
    "        \"dollar_discount_mae\",\n",
    "        \"available_qty_mean\",\n",
    "        \"available_qty_mae\",\n",
    "        \"proportion_cataloged\",\n",
    "        \"proportion_free_shipping\",\n",
    "        \"condition_mode\",\n",
    "        \"proportion_new\",\n",
    "        \"installments_mean\",\n",
    "        \"installments_mae\",\n",
    "        \"most_frequent_city\",\n",
    "        \"distinct_cities_count\",\n",
    "        \"proportion_has_gtin\",\n",
    "        \"num_attributes_mean\",\n",
    "        \"num_attributes_mae\",\n",
    "        \"num_attributes_median\",\n",
    "        \"available_amount_mean\",\n",
    "        \"available_amount_mae\",\n",
    "        \"available_amount_median\",\n",
    "        \"total_offers\",\n",
    "    ]\n",
    "]\n",
    "df_fields_ori = df_fields_ori.fillna(0)\n",
    "display(df_fields_ori.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a column is numeric\n",
    "def is_numeric(col):\n",
    "    return pd.api.types.is_numeric_dtype(col)\n",
    "\n",
    "\n",
    "# Iterate through the columns and apply frequency encoding if not numeric\n",
    "for column in df_fields_ori.columns:\n",
    "    if not is_numeric(df_fields_ori[column]):\n",
    "        # Apply frequency encoding to non-numeric columns\n",
    "        freq_encoding = df_fields_ori[column].value_counts().to_dict()\n",
    "        df_fields_ori.loc[:, column] = df_fields_ori[column].map(freq_encoding)\n",
    "\n",
    "display(df_fields_ori.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_components=6\n",
    "pca_col_list = [\"PC1\", \"PC2\", \"PC3\", \"PC4\", \"PC5\", \"PC6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔹 Passo 1: Selecionar as features relevantes\n",
    "df_fields = df_fields_ori.copy()  # Criar uma cópia para evitar avisos de mutação\n",
    "\n",
    "\n",
    "# 🔹 Passo 4: Normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_fields)\n",
    "\n",
    "# 🔹 Passo 1: Reduzir para 3 dimensões com PCA\n",
    "pca = PCA(n_components=pca_components)\n",
    "\n",
    "\n",
    "X_pca_3d = pca.fit_transform(X_scaled)\n",
    "\n",
    "\n",
    "\n",
    "# 🔹 Passo 3: Criar gráfico 3D com Plotly\n",
    "df_pca_normalized = pd.DataFrame(X_pca_3d, columns= pca_col_list)\n",
    "\n",
    "\n",
    "# Criar um dicionário para mapear seller_id -> subfolder_name\n",
    "seller_to_country = df.set_index(\"seller_id\")[\"subfolder_name\"].to_dict()\n",
    "# Mapear country_id para df_pca_normalized com base no seller_id\n",
    "df_pca_normalized[\"country_id\"] = df_grouped[\"seller_id\"].map(seller_to_country)\n",
    "\n",
    "\n",
    "# Criar o gráfico interativo\n",
    "\n",
    "\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    df_pca_normalized,\n",
    "\n",
    "    x=\"PC2\",\n",
    "    y=\"PC3\",\n",
    "    z=\"PC6\",\n",
    "\n",
    "    color=\"country_id\",\n",
    "\n",
    "    title=\"Clusters de Vendedores (PCA 3D - Normalizado)\",\n",
    "\n",
    "    color_continuous_scale=\"viridis\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Exibir o gráfico\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fields = df_fields_ori.copy()  # Criar uma cópia para evitar avisos de mutação\n",
    "# Get the indices of the top 3 highest values from each PCA column (PCA1, PCA2, PCA3)\n",
    "top_indices_pca1 = df_pca_normalized[\"PC6\"].idxmax()\n",
    "# Remove outliers (top 3 highest values for each PCA column) from df_fields\n",
    "outliers = []\n",
    "outliers.append(df_fields[top_indices_pca1-1:top_indices_pca1])\n",
    "df_fields = df_fields.drop(top_indices_pca1, axis=0)\n",
    "# Remover a linha com o maior valor de PC4\n",
    "df_pca_normalized = df_pca_normalized.drop(top_indices_pca1, axis=0)\n",
    "# Get the indices of the top 3 highest values from each PCA column (PCA1, PCA2, PCA3)\n",
    "top_indices_pca1 = df_pca_normalized[\"PC6\"].idxmin()\n",
    "# Remove outliers (top 3 highest values for each PCA column) from df_fields\n",
    "outliers = []\n",
    "outliers.append(df_fields[top_indices_pca1 - 1 : top_indices_pca1])\n",
    "df_fields = df_fields.drop(top_indices_pca1, axis=0)\n",
    "# Remover a linha com o maior valor de PC4\n",
    "df_pca_normalized = df_pca_normalized.drop(top_indices_pca1, axis=0)\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(\n",
    "    df_pca_normalized,\n",
    "\n",
    "    x=\"PC2\",\n",
    "    y=\"PC3\",\n",
    "    z=\"PC6\",\n",
    "\n",
    "    color=\"country_id\",\n",
    "\n",
    "    title=\"Clusters de Vendedores (PCA 3D - Normalizado)\",\n",
    "\n",
    "    color_continuous_scale=\"viridis\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Exibir o gráfico\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔹 Passo 5: Encontrar o número ideal de clusters (Método do Cotovelo)\n",
    "inertia = []\n",
    "K_range = range(1, 16)  # Testando de 1 a 10 clusters\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(df_pca_normalized.drop(columns=[\"country_id\"]))\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# 🔹 Passo 6: Plotar o Método do Cotovelo\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(K_range, inertia, marker=\"o\", linestyle=\"-\")\n",
    "plt.title(\"Método do Cotovelo\")\n",
    "plt.xlabel(\"Número de Clusters (k)\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    df_fields[\"cluster\"] = kmeans.fit_predict(\n",
    "        df_pca_normalized.drop(columns=[\"country_id\"])\n",
    "    )\n",
    "    try:\n",
    "        sil_score = silhouette_score(df_pca_normalized.drop(columns=[\"country_id\"]), df_fields[\"cluster\"])\n",
    "        print(f\"Silhouette Score: {sil_score:.4f} for k={k}\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 7: Aplicar K-Means com k escolhido\n",
    "kmeans = KMeans(n_clusters=6, random_state=42)\n",
    "df_fields[\"cluster\"] = kmeans.fit_predict(\n",
    "    df_pca_normalized.drop(columns=[\"country_id\"])\n",
    ")\n",
    "df_pca_normalized[\"cluster\"] = df_fields[\"cluster\"]\n",
    "# Passo 8: Visualizar os primeiros vendedores e seus clusters\n",
    "df_fields.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_col_list_c = [\"PC1\", \"PC2\", \"PC3\", \"PC4\", \"PC5\", \"PC6\",\"cluster\"]\n",
    "# Criar o gráfico interative\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    df_pca_normalized.drop(columns=[\"country_id\"])[pca_col_list_c],\n",
    "    x=\"PC2\",\n",
    "    y=\"PC3\",\n",
    "    z=\"PC6\",\n",
    "    color=\"cluster\",\n",
    "    title=\"Clusters de Vendedores (PCA 3D - Normalizado)\",\n",
    "    labels={\n",
    "        \"PC2\": \"Componente Principal 2 (Normalizado)\",\n",
    "        \"PC5\": \"Componente Principal 5 (Normalizado)\",\n",
    "        \"PC6\": \"Componente Principal 6 (Normalizado)\",\n",
    "    },\n",
    "    color_continuous_scale=\"viridis\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Exibir o gráfico\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_fields[\"cluster\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_pca = df_pca_normalized.drop(columns=[\"country_id\"])[[\n",
    "    \"PC2\", \"PC3\", \"PC6\", \"cluster\"\n",
    "]]\n",
    "df_best_pca = df_best_pca.rename(columns={\"PC2\": \"PC1\", \"PC3\": \"PC2\", \"PC6\": \"PC3\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔹 Passo 5: Encontrar o número ideal de clusters (Método do Cotovelo)\n",
    "inertia = []\n",
    "K_range = range(1, 16)  # Testando de 1 a 10 clusters\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(df_best_pca.drop(columns=[\"cluster\"]))\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# 🔹 Passo 6: Plotar o Método do Cotovelo\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(K_range, inertia, marker=\"o\", linestyle=\"-\")\n",
    "plt.title(\"Método do Cotovelo\")\n",
    "plt.xlabel(\"Número de Clusters (k)\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    df_fields[\"cluster\"] = kmeans.fit_predict(\n",
    "        df_best_pca.drop(columns=[\"cluster\"])\n",
    "    )\n",
    "    try:\n",
    "        sil_score = silhouette_score(df_best_pca.drop(columns=[\"cluster\"]), df_fields[\"cluster\"])\n",
    "        print(f\"Silhouette Score: {sil_score:.4f} for k={k}\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 7: Aplicar K-Means com k escolhido\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "df_fields[\"cluster\"] = kmeans.fit_predict(df_best_pca.drop(columns=[\"cluster\"]))\n",
    "df_best_pca[\"cluster\"] = df_fields[\"cluster\"]\n",
    "# Passo 8: Visualizar os primeiros vendedores e seus clusters\n",
    "df_fields.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(\n",
    "    df_best_pca,\n",
    "    x=\"PC1\",\n",
    "    y=\"PC2\",\n",
    "    z=\"PC3\",\n",
    "    color=\"cluster\",\n",
    "    title=\"Clusters de Vendedores (PCA 3D - Normalizado)\",\n",
    "    labels={\n",
    "        \"PC2\": \"Componente Principal 2 (Normalizado)\",\n",
    "        \"PC5\": \"Componente Principal 5 (Normalizado)\",\n",
    "        \"PC6\": \"Componente Principal 6 (Normalizado)\",\n",
    "    },\n",
    "    color_continuous_scale=\"viridis\",\n",
    ")\n",
    "\n",
    "\n",
    "# Exibir o gráfico\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_fields[\"cluster\"].value_counts())\n",
    "display(df_fields[df_fields[\"cluster\"] == 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o layout para os subgráficos (3 subgráficos por cluster)\n",
    "fig = make_subplots(\n",
    "    rows=len(set(df_best_pca[\"cluster\"])),\n",
    "    cols=3,  # Uma linha por cluster, 3 colunas para cada par de componentes PCA\n",
    "    subplot_titles=[\"PCA1 vs PCA2\", \"PCA2 vs PCA3\", \"PCA1 vs PCA3\"],\n",
    "    specs=[\n",
    "        [{\"type\": \"scatter\"}, {\"type\": \"scatter\"}, {\"type\": \"scatter\"}]\n",
    "        for _ in range(len(set(df_best_pca[\"cluster\"])))\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Loop para cada cluster e adicionar os gráficos\n",
    "for i, cluster in enumerate(set(df_best_pca[\"cluster\"])):\n",
    "    cluster_data = df_best_pca[df_best_pca[\"cluster\"] == cluster]\n",
    "\n",
    "    # PCA1 vs PCA2 plot\n",
    "    scatter1 = go.Scatter(\n",
    "        x=cluster_data[\"PC1\"],\n",
    "        y=cluster_data[\"PC2\"],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=cluster_data[\"cluster\"], colorscale=\"viridis\"),\n",
    "        name=f\"Cluster {cluster} (PCA1 vs PCA2)\",\n",
    "    )\n",
    "    fig.add_trace(scatter1, row=i + 1, col=1)\n",
    "\n",
    "    # PCA2 vs PCA3 plot\n",
    "    scatter2 = go.Scatter(\n",
    "        x=cluster_data[\"PC2\"],\n",
    "        y=cluster_data[\"PC3\"],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=cluster_data[\"cluster\"], colorscale=\"viridis\"),\n",
    "        name=f\"Cluster {cluster} (PCA2 vs PCA3)\",\n",
    "    )\n",
    "    fig.add_trace(scatter2, row=i + 1, col=2)\n",
    "\n",
    "    # PCA1 vs PCA3 plot\n",
    "    scatter3 = go.Scatter(\n",
    "        x=cluster_data[\"PC1\"],\n",
    "        y=cluster_data[\"PC3\"],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=cluster_data[\"cluster\"], colorscale=\"viridis\"),\n",
    "        name=f\"Cluster {cluster} (PCA1 vs PCA3)\",\n",
    "    )\n",
    "    fig.add_trace(scatter3, row=i + 1, col=3)\n",
    "\n",
    "# Definir os intervalos para todos os subgráficos de forma que os eixos sejam fixos para cada tipo de comparação\n",
    "fig.update_layout(\n",
    "    title=\"Clusters de Vendedores (PCA 2D Comparisons)\",\n",
    "    height=3000,\n",
    "    width=3000\n",
    ")\n",
    "\n",
    "# Exibir a figura\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter a matriz de cargas (loadings)\n",
    "pca_components = pd.DataFrame(\n",
    "    pca.components_,  # Coeficientes do PCA\n",
    "    columns=df_fields.drop(columns=['cluster']).columns,  # Nome das variáveis originais\n",
    "    index=[f\"PC{i+1}\" for i in range(pca.n_components_)],  # Nome dos componentes\n",
    ")\n",
    "\n",
    "# Exibir a matriz de cargas dos 3 primeiros PCs\n",
    "pca_components.T.sort_values(by=\"PC1\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholds\n",
    "upper_threshold = 0.2\n",
    "lower_threshold = -0.1\n",
    "\n",
    "relevant_fields = {}\n",
    "\n",
    "# Filtrar variáveis com pesos maiores que 0.2 ou menores que -0.1\n",
    "for pc in pca_components.index:\n",
    "    relevant_fields[pc] = pca_components.T[pc][\n",
    "        (pca_components.T[pc] >= upper_threshold)\n",
    "        | (pca_components.T[pc] <= lower_threshold)\n",
    "    ]\n",
    "\n",
    "# Criar o gráfico de barras interativo para os 3 primeiros componentes principais (PC1, PC2, PC3)\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=3,  # 1 linha com 3 colunas\n",
    "    subplot_titles=[\"Pesos do PCA1\", \"Pesos do PCA2\", \"Pesos do PCA3\"],\n",
    ")\n",
    "\n",
    "# Gráfico para PC1\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=relevant_fields[\"PC1\"].index,  # Variáveis relevantes\n",
    "        y=relevant_fields[\"PC1\"].values,  # Pesos relevantes\n",
    "        name=\"PC1\",\n",
    "        marker_color=\"royalblue\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "# Gráfico para PC2\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=relevant_fields[\"PC2\"].index,  # Variáveis relevantes\n",
    "        y=relevant_fields[\"PC2\"].values,  # Pesos relevantes\n",
    "        name=\"PC2\",\n",
    "        marker_color=\"orange\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "# Gráfico para PC3\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=relevant_fields[\"PC3\"].index,  # Variáveis relevantes\n",
    "        y=relevant_fields[\"PC3\"].values,  # Pesos relevantes\n",
    "        name=\"PC3\",\n",
    "        marker_color=\"green\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=3,\n",
    ")\n",
    "\n",
    "# Atualizar o layout para que fique mais legível\n",
    "fig.update_layout(\n",
    "    title=\"Pesos Relevantes dos Componentes Principais (PCA)\",\n",
    "    height=600,\n",
    "    showlegend=False,\n",
    "    xaxis=dict(tickangle=90),  # Rotaciona os rótulos do eixo X\n",
    "    xaxis2=dict(tickangle=90),  # Rotaciona os rótulos do eixo X para o segundo gráfico\n",
    "    xaxis3=dict(tickangle=90),  # Rotaciona os rótulos do eixo X para o terceiro gráfico\n",
    "    barmode=\"group\",  # Organiza as barras em grupos\n",
    ")\n",
    "\n",
    "# Exibir o gráfico interativo\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_fields is your DataFrame and has a 'cluster' column\n",
    "X = df_fields.drop(columns=\"cluster\").values  # Features\n",
    "y = df_fields[\"cluster\"].values  # Labels (or clusters)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Perform PCA with 2 components for visualization\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "\n",
    "# Create a Plotly biplot\n",
    "def plot_biplot(score, coeff, labels=None):\n",
    "    xs = score[:, 0]\n",
    "    ys = score[:, 1]\n",
    "    n = coeff.shape[0]\n",
    "\n",
    "    # Create the figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Scatter plot for the PCA scores (data points)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=xs,\n",
    "            y=ys,\n",
    "            mode=\"markers\",\n",
    "            marker=dict(\n",
    "                color=y, colorscale=\"Viridis\", showscale=True\n",
    "            ),  # Color by clusters\n",
    "            name=\"PCA points\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Adding arrows for each feature (vectors)\n",
    "    for i in range(n):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[0, coeff[i, 0]],  # Start from the origin\n",
    "                y=[0, coeff[i, 1]],  # End at the component direction\n",
    "                mode=\"lines+text\",\n",
    "                line=dict(color=\"red\", width=2),\n",
    "                text=[\n",
    "                    None,\n",
    "                    labels[i] if labels is not None else f\"Var{i + 1}\",\n",
    "                ],  # Feature label\n",
    "                textposition=\"top center\",\n",
    "                name=f\"Feature {labels[i]}\" if labels is not None else f\"Var{i + 1}\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Layout settings\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"PC1\",\n",
    "        yaxis_title=\"PC2\",\n",
    "        showlegend=True,\n",
    "        template=\"plotly_dark\",  # Dark theme (optional)\n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "# Call the plotting function\n",
    "plot_biplot(\n",
    "    X_pca[:, 0:2], pca.components_.T, labels=df_fields.columns\n",
    ")  # Feature names as labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_fields is your DataFrame and has a 'cluster' column\n",
    "X = df_fields.drop(columns=\"cluster\").values  # Features\n",
    "y = df_fields[\"cluster\"].values  # Labels (or clusters)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Perform PCA with 2 components for visualization\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "\n",
    "# Create a Plotly biplot\n",
    "def plot_biplot(score, coeff, labels=None):\n",
    "    xs = score[:, 0]\n",
    "    ys = score[:, 1]\n",
    "    n = coeff.shape[0]\n",
    "\n",
    "    # Create the figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Scatter plot for the PCA scores (data points)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=xs,\n",
    "            y=ys,\n",
    "            mode=\"markers\",\n",
    "            marker=dict(\n",
    "                color=y, colorscale=\"Viridis\", showscale=True\n",
    "            ),  # Color by clusters\n",
    "            name=\"PCA points\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Adding arrows for each feature (vectors)\n",
    "    for i in range(n):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[0, coeff[i, 0]],  # Start from the origin\n",
    "                y=[0, coeff[i, 1]],  # End at the component direction\n",
    "                mode=\"lines+text\",\n",
    "                line=dict(color=\"red\", width=2),\n",
    "                text=[\n",
    "                    None,\n",
    "                    labels[i] if labels is not None else f\"Var{i + 1}\",\n",
    "                ],  # Feature label\n",
    "                textposition=\"top center\",\n",
    "                name=f\"Feature {labels[i]}\" if labels is not None else f\"Var{i + 1}\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Layout settings\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"PC2\",\n",
    "        yaxis_title=\"PC3\",\n",
    "        showlegend=True,\n",
    "        template=\"plotly_dark\",  # Dark theme (optional)\n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "# Call the plotting function\n",
    "plot_biplot(\n",
    "    X_pca[:, 1:3], pca.components_.T, labels=df_fields.columns\n",
    ")  # Feature names as labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_summary = df_fields.groupby(\"cluster\").mean()\n",
    "# Variáveis numéricas para gerar boxplots\n",
    "numeric_cols = df_cluster_summary.columns\n",
    "\n",
    "# Gerar boxplots para cada variável numérica usando facet_col\n",
    "for col in numeric_cols:\n",
    "    fig = px.box(\n",
    "        df_fields,\n",
    "        x=\"cluster\",  # Eixo X representando os clusters\n",
    "        y=col,  # Variável numérica\n",
    "        title=f\"Distribuição de {col} por Cluster\",\n",
    "        labels={\"cluster\": \"Cluster\", col: f\"{col} Value\"},  # Rótulos dos eixos\n",
    "        color=\"cluster\",  # Colorir os boxplots por cluster\n",
    "        boxmode=\"group\",  # Organizar os boxplots em grupos\n",
    "    )\n",
    "\n",
    "    # Exibir o gráfico interativo\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_summary_r = df_cluster_summary.reset_index()\n",
    "df_cluster_summary_tr = df_cluster_summary_r.T.drop(\"cluster\", axis = 0)\n",
    "df_cluster_summary_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heatmap = df_cluster_summary_tr\n",
    "# Create subplots for each feature (row)\n",
    "fig = make_subplots(\n",
    "    rows=len(df_heatmap.index),\n",
    "    cols=1,\n",
    "    shared_xaxes=True,\n",
    "    vertical_spacing=0.02,\n",
    "    subplot_titles=[],  # Row titles will be the feature names\n",
    ")\n",
    "\n",
    "# For each row (feature), add a heatmap with its own color scale\n",
    "for i, feature in enumerate(df_heatmap.index):\n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=[df_heatmap.loc[feature].values],  # Select values for this row\n",
    "            x=df_heatmap.columns,  # Cluster labels (columns)\n",
    "            y=[feature],  # Feature label (row)\n",
    "            colorscale=\"YlGnBu\",  # Choose a color scale\n",
    "            colorbar=dict(title=\"Feature Value\"),\n",
    "            showscale=True,  # Display the color scale for each row\n",
    "            zmin=df_heatmap.loc[feature].min(),  # Set color scale minimum for this row\n",
    "            zmax=df_heatmap.loc[feature].max(),  # Set color scale maximum for this row\n",
    "        ),\n",
    "        row=i + 1,\n",
    "        col=1,  # Place the heatmap in the corresponding subplot row\n",
    "    )\n",
    "\n",
    "# Update layout for better presentation\n",
    "fig.update_layout(\n",
    "    height=1500,  # Adjust height as needed\n",
    "    width=1500,  # Adjust width as needed\n",
    "    showlegend=False,\n",
    ")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    title_text=\"Clusters\",  # X-axis titl\n",
    "    row=len(df_heatmap.index),  # Apply title to the last row\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.update_yaxes(\n",
    "    title_text=\"Features\",  # X-axis title\n",
    "    row=len(df_heatmap.index) // 2,  # Apply title to the last row\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
